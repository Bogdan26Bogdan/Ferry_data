{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a7ccc9-000f-4413-af69-72b98cc1db3f",
   "metadata": {},
   "source": [
    "To install a package over pip so that it works in the notebook you have to run: \n",
    "```bash\n",
    "$ source /opt/tljh/user/bin/activate\n",
    "$ pip install <package name>\n",
    "```\n",
    "and then restart the ipykernal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db132ef9-78ad-49c0-91e9-0e65393ea991",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3ccc6-9f24-4625-8bf1-aeba5f17afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ferryFile\n",
    "import port\n",
    "import numpy as np\n",
    "import heapq\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt \n",
    "import matplotlib_inline\n",
    "import itertools\n",
    "from typing import Dict, Set\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38716986-bdf7-47e5-8d58-2cb9a9c217d8",
   "metadata": {},
   "source": [
    "Load the trip times from the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d204a1-2464-467e-90e5-69126a68912d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_date(file_name: str) -> str:\n",
    "    \"\"\"Time is in the format of YYYY-MM-DD-HH-MM-SS\"\"\"\n",
    "    return (\"-\".join(file_name.split(\"_\")[1].split(\"-\")[0:6])).split(\".\")[0]\n",
    "\n",
    "def get_week_day(time: str) -> str:\n",
    "    \"\"\"Returns 0-6 for monday through sunday for the given date. \n",
    "    Expects the time in YYYY-MM-DD-HH-MM-SS\"\"\"\n",
    "\n",
    "    return datetime.datetime.strptime(time, \"%Y-%m-%d-%H-%M-%S\").weekday()\n",
    "\n",
    "\n",
    "def load_trip_times_and_ports_from_files(directory: str = None) -> Set: \n",
    "    \"\"\"Returns a set of the ports and dictionary of trip times in minutes with the keys being the route codes + the index of the day of the week, \n",
    "    based off the sailing durations in the files.\"\"\"\n",
    "    if directory == None: \n",
    "        directory = \"../BC_Ferries_API_DATA/\"\n",
    "\n",
    "    ports = set()\n",
    "    trip_times = {}\n",
    "    \n",
    "        \n",
    "    for file in os.listdir(directory):\n",
    "        with open(directory + file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            possible_keys = ['routes', 'capacityRoutes', 'nonCapacityRoutes']\n",
    "            #print(get_date(file))\n",
    "            #print(get_week_day(get_date(file)))\n",
    "            week_day = str(get_week_day(get_date(file)))\n",
    "\n",
    "            if str(type(data)) == \"<class 'str'>\":\n",
    "                #print(f\"Type of data is string: {data}\")\n",
    "                #print(\"Continuing.\")\n",
    "                continue\n",
    "\n",
    "            if 'routes' in data.keys():\n",
    "                for route in data['routes']:\n",
    "                    from_port = route['fromTerminalCode']\n",
    "                    to_port = route['toTerminalCode']\n",
    "                    ports.add(from_port)\n",
    "                    ports.add(to_port)\n",
    "\n",
    "                    route_code = route['routeCode']\n",
    "                    assert route_code == from_port + to_port, \"Sanity check that the route code is from_port+to_port\"\n",
    "\n",
    "                    route_code = route_code \n",
    "                    \n",
    "                    trip_time = route['sailingDuration']\n",
    "                    if trip_time == \"\":\n",
    "                        #print(\"Trip time is empty. Continuing\")\n",
    "                        continue\n",
    "                    if \":\" in trip_time: \n",
    "                        #then the format is %H:%M\n",
    "                        hours, minutes = trip_time.split(\":\")\n",
    "                    else:\n",
    "                        #then the format is \"%Hh %%Mm\"\n",
    "                        hours, minutes = trip_time.split(\" \")\n",
    "                        hours = hours.strip(\"h\")\n",
    "                        minutes = minutes.strip(\"m\")\n",
    "\n",
    "                        \n",
    "\n",
    "                    trip_time_in_minutes = 60 * int(hours) + int(minutes)\n",
    "\n",
    "                    # Since the scraped data has multiple routs from one port to another, \n",
    "                    # we are only going to pay attention to the direct route, ie take the min\n",
    "                    if route_code in trip_times.keys():\n",
    "                        if trip_times[route_code] > trip_time_in_minutes:\n",
    "                            trip_times[route_code] = trip_time_in_minutes\n",
    "                    else:\n",
    "                        trip_times[route_code] = trip_time_in_minutes\n",
    "                \n",
    "                    \n",
    "\n",
    "    return ports, trip_times\n",
    "\n",
    "\n",
    "PORT_CODES, TRIP_TIMES = load_trip_times_and_ports_from_files()\n",
    "print(TRIP_TIMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf53d307-676b-4b21-89a2-111b8aab3677",
   "metadata": {},
   "source": [
    "Constants and Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6968009-62fe-4b4f-a268-40150d9a9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SIMULATION_TIME = 1000\n",
    "\n",
    "\n",
    "MEAN_TRIP_TIME = 20\n",
    "SD_TRIP_TIME = 1.5\n",
    "MEAN_LOADING_UNLOADING_TIME = 10\n",
    "SD_LOADING_UNLOADING_TIME = 1\n",
    "\n",
    "\n",
    "FERRIES = []\n",
    "SEEDS = [234,4234,324,325543,2,34,546,74,567,568,568,89,364575,342,45,3456473,546,3456473]\n",
    "SEEDS = set(SEEDS)\n",
    "\n",
    "# Programmatically create the port objects for each of the port codes\n",
    "for port_code in PORT_CODES:\n",
    "    globals()[port_code] = port.Port() \n",
    "    globals()[port_code].port_code = port_code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95724805-1974-4443-b154-7e7fb86b32d0",
   "metadata": {},
   "source": [
    "To generate the cdf we can use np.norm.cdf(val, loc, scale) where location is the mean and scale is the standard deviation. \n",
    "To find the values for a certain percent we can use ppf from scipy stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5603109a-2a3d-4a51-bdeb-40cd5115ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scheduled_departure_and_arrival_times(arrival, departure, trip_length, wanted_on_time_percent: float = 0.85) -> None:\n",
    "    trip_distribution = scipy.stats.norm(loc=MEAN_TRIP_TIME, scale=SD_TRIP_TIME)\n",
    "    loading_unloading_distribution = scipy.stats.norm(loc=MEAN_LOADING_UNLOADING_TIME, scale=SD_LOADING_UNLOADING_TIME)\n",
    "\n",
    "    current_time = 0\n",
    "    for i in range(1, trip_length):\n",
    "        # Add the time to get to the next port\n",
    "        current_time += trip_distribution.ppf(wanted_on_time_percent)\n",
    "\n",
    "        # Set the expected arrival time\n",
    "        arrival[i] = current_time\n",
    "\n",
    "        # Add the time to load and unload at that port\n",
    "        current_time += loading_unloading_distribution.ppf(wanted_on_time_percent)\n",
    "\n",
    "        #Set the expected departure time\n",
    "        departure[i] = current_time\n",
    "\n",
    "    for i in range(len(arrival)):\n",
    "        if type(arrival[i]) not in [int, float]:\n",
    "            arrival[i] = arrival[i].item()\n",
    "    for i in range(len(departure)):\n",
    "        if type(departure[i]) not in [int, float]:\n",
    "            departure[i] = departure[i].item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10919f80-1cde-4203-922a-f712c7682b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_arrival = [ 0 for i in range(4)]\n",
    "expected_departure = [0 for i in range(4)]\n",
    "\n",
    "generate_scheduled_departure_and_arrival_times(expected_arrival, expected_departure, 4, 0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b345d7-3c54-4708-a182-a0467e7ea983",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_to_count_as_late = 0\n",
    "lates_for_each = {}\n",
    "for ppf_value in range(1, 100, 1):\n",
    "    ppf_value = ppf_value / 100\n",
    "    lates_for_each[ppf_value] = []\n",
    "\n",
    "    expected_arrival = [ 0 for i in range(4)]\n",
    "    expected_departure = [0 for i in range(4)]\n",
    "    generate_scheduled_departure_and_arrival_times(expected_arrival, expected_departure, 4, ppf_value)\n",
    "    \n",
    "    for seed_value in SEEDS:\n",
    "        np.random.seed(seed_value)\n",
    "        # Most of the trips take the same amount of time independent of the ferry \n",
    "        # Makes every port to every other port take 20ish minutes. \n",
    "        # Times are made to be the same independent of direction.\n",
    "        TRIP_TIMES = {}\n",
    "        for port in PORT_CODES:\n",
    "            for other_port in [i for i in PORT_CODES if i != port]:\n",
    "                if other_port + port in TRIP_TIMES.keys():\n",
    "                    TRIP_TIMES[port+other_port] = TRIP_TIMES[other_port+port]\n",
    "                else:\n",
    "                    TRIP_TIMES[port + other_port] = np.random.normal(MEAN_TRIP_TIME, SD_TRIP_TIME)\n",
    "    \n",
    "        # Set the loading and unloading times\n",
    "        # Port + Current_time for every 5 step increment\n",
    "        LOADING_AND_UNLOADING_TIMES = {}\n",
    "        for port_code in PORT_CODES:\n",
    "            for time in range(0, MAX_SIMULATION_TIME, 5):\n",
    "                LOADING_AND_UNLOADING_TIMES[globals()[port_code] + time] = np.random.normal(MEAN_LOADING_UNLOADING_TIME, SD_LOADING_UNLOADING_TIME)\n",
    "        \n",
    "\n",
    "        \n",
    "        #Create a ferry object\n",
    "        QNW = ferryFile.Ferry()\n",
    "        QNW.ferry_name = \"Queen of New Westminster\"\n",
    "        QNW.ferry_code = \"QNW\"\n",
    "        QNW.ferry_capacity = 150\n",
    "        QNW.ferry_route = [TSA, SWB, TSA]\n",
    "        QNW.ferry_trip_time = TRIP_TIMES\n",
    "        QNW.set_expected_departure_times(expected_departure)\n",
    "        QNW.set_expected_arrival_times(expected_arrival)\n",
    "        QNW.loading_unloading_time = LOADING_AND_UNLOADING_TIMES\n",
    "        QNW.trips_required = 1\n",
    "        \n",
    "        QNW.trips_completed = 0\n",
    "        QNW.ferry_current_port_index = 0\n",
    "        QNW.validate_arrival_and_departure_times()\n",
    "\n",
    "        QNW.print_stats_at_end = True\n",
    "\n",
    "        QNW.validate_arrival_and_departure_times()\n",
    "    \n",
    "        current_time =0\n",
    "        event_queue = []\n",
    "        heapq.heapify(event_queue)\n",
    "        heapq.heappush(event_queue, (current_time, QNW))\n",
    "        \n",
    "    \n",
    "        current_event = heapq.heappop(event_queue)\n",
    "        while current_event[1].next_function != None:\n",
    "            current_time = current_event[0]\n",
    "    \n",
    "            next_event_time = current_event[1].next_function(current_time)\n",
    "            heapq.heappush(event_queue, (next_event_time, current_event[1]))\n",
    "    \n",
    "            current_event = heapq.heappop(event_queue)\n",
    "\n",
    "        lates_for_each[ppf_value].append(QNW.total_times_late(time_to_count_as_late))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(lates_for_each)\n",
    "for key in lates_for_each.keys():\n",
    "    data = lates_for_each[key]\n",
    "    times_late_to_arrive = [i[0] for i in data]\n",
    "    times_late_to_depart = [i[1] for i in data]\n",
    "\n",
    "    times_late_to_arrive = sum(times_late_to_arrive) / len(times_late_to_arrive)\n",
    "    times_late_to_depart = sum(times_late_to_depart) / len(times_late_to_depart)\n",
    "\n",
    "    lates_for_each[key] = [times_late_to_arrive, times_late_to_depart]\n",
    "#print(lates_for_each)\n",
    "\n",
    "plt.bar(lates_for_each.keys(), [lates_for_each[key][0] for key in lates_for_each.keys()], 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb70b9a-7c2d-444f-8364-a56dbc120f52",
   "metadata": {},
   "source": [
    "Use pandas to load data from csv - Keep in mind to run this locally, and not upload the files to github or the jupyter server!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b8133-e6c4-438c-a7bb-38432960cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are some pandas examples\n",
    "data_file = None\n",
    "\n",
    "#Load data from file\n",
    "#all_data = pd.read_csv(file)\n",
    "data = {\"date_key\": [\"2024-04-0\" + str(i) for i in range(1,10)]}\n",
    "for i in range(10,28):\n",
    "    data[\"date_key\"].append(\"2024-04-\" + str(i))\n",
    "all_data = pd.DataFrame(data = data)\n",
    "\n",
    "#Seperate data by day of the week\n",
    "all_data['day_of_the_week'] = [datetime.datetime.strptime(i, \"%Y-%m-%d\").weekday() for i in all_data['date_key']]\n",
    "\n",
    "#Add route code\n",
    "all_data[\"route_id\"] = np.random.choice([5,9], all_data.shape[0])\n",
    "\n",
    "all_data.loc[all_data[\"route_id\"] == 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c48ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the year for the data from the file name\n",
    "def get_year(file_name: str) -> str:\n",
    "    print(file_name)\n",
    "    file_name = file_name.split(\"fy\")[1].strip(\".csv\").strip(\"fy\")\n",
    "    if \"_\" in file_name:\n",
    "        return file_name.split(\"_\")[0]\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71bde22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adds a date key to the data  to make it easier to filter\n",
    "def add_date_key(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    #If the data set is analyze or event then there is a \"date_key\" column exclusive of the end date\n",
    "    if \"date_key\" in data.columns: \n",
    "        #Date is in the format of YYYY-MM-DD\n",
    "        data[\"date_key\"] = pd.to_datetime(data[\"date_key\"])\n",
    "\n",
    "    #If it is injest then there is a \"Sched Dept Ts\" column\n",
    "    elif \"Sched Dept Ts\" in data.columns: \n",
    "        #Date is the format of YYYY-MM-DD-HH-MM-SS\n",
    "        data[\"date_key\"] = pd.to_datetime(data[\"Sched Dept Ts\"])\n",
    "\n",
    "    #Throw an error to show that we have a data set without the proper columns\n",
    "    else: \n",
    "        print(\"A data set was passed that did not follow any of the formats\")\n",
    "        assert(False)\n",
    "        \n",
    "\n",
    "def filter_by_dates(data: pd.DataFrame, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    # Filter the data set by the start and end date and return the new data set\n",
    "    if type(start_date) is not datetime.datetime:\n",
    "        start_date = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    if type(end_date) is not datetime.datetime:\n",
    "        end_date = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "    assert(start_date <= end_date), \"Start date must be before end date\"\n",
    "\n",
    "    new_data = data.loc[data[\"date_key\"] >= start_date & data[\"date_key\"] < end_date]\n",
    "\n",
    "    return new_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fbadd73-9ccc-47d8-bbf0-ff776207ee5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10083/1878275666.py:9: DtypeWarning: Columns (0,1,2,7,9,10,11,12,13,14,15,16,17,18,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_analyze_data = pd.concat(map(pd.read_csv, [ANALYZE_FOLDER + \"/\" + file for file in files]))\n",
      "/tmp/ipykernel_10083/1878275666.py:9: DtypeWarning: Columns (0,1,2,7,9,10,11,12,13,14,15,16,17,18,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_analyze_data = pd.concat(map(pd.read_csv, [ANALYZE_FOLDER + \"/\" + file for file in files]))\n",
      "/tmp/ipykernel_10083/1878275666.py:9: DtypeWarning: Columns (0,1,2,7,9,10,11,12,13,14,15,16,17,18,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_analyze_data = pd.concat(map(pd.read_csv, [ANALYZE_FOLDER + \"/\" + file for file in files]))\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "assert(load_dotenv())\n",
    "\n",
    "ANALYZE_FOLDER = os.getenv(\"SAILING_ANALYZE_FOLDER\")\n",
    "INGEST_FOLDER = os.getenv(\"SAILING_INGEST_FOLDER\")\n",
    "EVENT_FOLDER = os.getenv(\"SAILING_EVENT_FOLDER\")\n",
    "\n",
    "files = os.listdir(ANALYZE_FOLDER) \n",
    "all_analyze_data = pd.concat(map(pd.read_csv, [ANALYZE_FOLDER + \"/\" + file for file in files]))\n",
    "all_analyze_data.dropna(how='all', inplace=True, ignore_index=True)\n",
    "\n",
    "def convert_to_epoch(date: str):\n",
    "    dt_obj = datetime.datetime.strptime(date, \"%Y-%m-%d %H:%M\")\n",
    "    return int(dt_obj.timestamp())\n",
    "\n",
    "all_analyze_data[\"arrival_actual_datetime\"] = all_analyze_data[\"arrival_actual_datetime\"].apply(convert_to_epoch)\n",
    "all_analyze_data[\"departure_actual_datetime\"] = all_analyze_data[\"departure_actual_datetime\"].apply(convert_to_epoch)\n",
    "\n",
    "all_analyze_data[\"sailing_time\"] = (all_analyze_data[\"arrival_actual_datetime\"] - all_analyze_data[\"departure_actual_datetime\"])/60\n",
    "add_date_key(all_analyze_data)\n",
    "assert(all_analyze_data.loc[all_analyze_data[\"sailing_time\"] <= 0].empty) #Sanity check that none of the boats are time travellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c19802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add loading and unloading time array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887d0d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(EVENT_FOLDER)\n",
    "eventData = pd.concat(map(pd.read_csv, [EVENT_FOLDER + \"/\" + file for file in files])) #Read all the files and concatenate them into one dataframe\n",
    "eventData.dropna(how=\"all\", inplace=True, ignore_index=True)\n",
    "\n",
    "arr_ports = [int(i) for i in  eventData[\"arr_port_id\"].unique()]\n",
    "dep_ports = [int(i) for i in  eventData[\"dep_port_id\"].unique()]\n",
    "\n",
    "ports = set(arr_ports + dep_ports)\n",
    "\n",
    "portID_to_port_map = {}\n",
    "for port in ports: \n",
    "    #Check arrivals \n",
    "    port_abb_arr = eventData.loc[eventData[\"arr_port_id\"] == port][\"arr_port_abb\"].unique()\n",
    "\n",
    "    #Check departures\n",
    "    port_abb_dep = eventData.loc[eventData[\"dep_port_id\"] == port][\"dep_port_abb\"].unique()\n",
    "\n",
    "    #Verify that one the abbreviation was found for atleast 1 and if it was found for only one assign it to both.\n",
    "    if len(port_abb_dep) == 0 and len(port_abb_arr) == 0: \n",
    "        print(f\"Could not find the abbreviation for {port}.\")\n",
    "        continue\n",
    "    elif len(port_abb_dep) == 0: \n",
    "        port_abb_dep = port_abb_arr\n",
    "    elif len(port_abb_arr) == 0:\n",
    "        port_abb_arr = port_abb_dep\n",
    "\n",
    "    port_abb_arr = port_abb_arr[0]\n",
    "    port_abb_dep = port_abb_dep[0]\n",
    "    \n",
    "    \n",
    "    assert(port_abb_dep == port_abb_arr)\n",
    "\n",
    "    if port in portID_to_port_map.keys():\n",
    "        assert(portID_to_port_map[port] == port_abb_arr) #Sanity check\n",
    "    else: \n",
    "        portID_to_port_map[port] = port_abb_arr\n",
    "\n",
    "    \n",
    "def portID_to_abb(portID:int | str) -> str: \n",
    "    if type(portID) is str: \n",
    "        portID = int(portID)\n",
    "\n",
    "    return portID_to_port_map[portID]\n",
    "\n",
    "portID_to_port_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31d1971",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURES_DIR = \"figures\"\n",
    "\n",
    "#Seperate data by route\n",
    "Route5_data = all_analyze_data.loc[(all_analyze_data[\"route_id\"] == 5)]\n",
    "Route9_data = all_analyze_data.loc[all_analyze_data[\"route_id\"] == 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9dfd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_port_from_route(route_data, route_leg_id, arrival: bool = False, departure: bool = False):\n",
    "    if arrival and departure:\n",
    "        raise ValueError(\"Both arrival and departure cannot be true\")\n",
    "    if not arrival and not departure:\n",
    "        raise ValueError(\"Either arrival or departure must be true\")\n",
    "    if arrival:\n",
    "        key = \"arr_port_id\"\n",
    "    else:\n",
    "        assert(departure)\n",
    "        key = \"dep_port_id\"\n",
    "\n",
    "\n",
    "    port_id = route_data[route_data[\"route_leg_id\"] == route_leg_id][key].unique()\n",
    "    assert(len(port_id) == 1)\n",
    "    port_id = port_id[0]\n",
    "    return port_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e90867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make histograms for each of the legs with all of the vessels to see the general distribution of sailing times\n",
    "def make_histograms_for_legs(route_data: pd.DataFrame) -> None:\n",
    "    route_vessels = route_data[\"vessel_id\"].unique()\n",
    "    route_legs = route_data[\"route_leg_id\"].unique()\n",
    "\n",
    "\n",
    "    for route_leg_id in route_legs: \n",
    "        #Get the arrival and departure port ids\n",
    "        arrival_port_id = portID_to_abb(str(int(get_port_from_route(route_data, route_leg_id, arrival=True))))\n",
    "        departure_port_id = portID_to_abb(str(int(get_port_from_route(route_data, route_leg_id, departure=True))))\n",
    "\n",
    "        route_figure = plt.figure()\n",
    "        plt.title(f\"Route {route_leg_id.split('-')[0]}, Leg {arrival_port_id} to {departure_port_id}\")\n",
    "        plt.xlabel(\"Sailing Time (m)\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        \n",
    "        for vessel in route_vessels: \n",
    "            #verify the vessel has sailed on the route otherwise skip\n",
    "            if route_data.loc[(route_data[\"vessel_id\"] == vessel) & (route_data[\"route_leg_id\"] == route_leg_id)].empty:\n",
    "                continue\n",
    "\n",
    "            #plot the histogram\n",
    "            route_data.loc[(route_data[\"vessel_id\"] == vessel) & (route_data[\"route_leg_id\"] == route_leg_id)][\"sailing_time\"].hist(bins=15, alpha=0.3, label=f\"Vessel {vessel}\")\n",
    "\n",
    "        #format the plot\n",
    "        plt.grid(False)\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{FIGURES_DIR}/R{route_leg_id.split('-')[0]}_{departure_port_id + arrival_port_id}_histogram.png\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "make_histograms_for_legs(Route5_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e8cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make plots for the sailing times on each route for each vessel to check if the timing is consistent across vessels.\n",
    "def make_subplot_histograms_for_legs(route_data: pd.DataFrame) -> None:\n",
    "    route_vessels = route_data[\"vessel_id\"].unique()\n",
    "    route_legs = route_data[\"route_leg_id\"].unique()\n",
    "\n",
    "    for route_leg_id in route_legs: \n",
    "        #Get the arrival, departure port ids and the route id\n",
    "        arrival_port_id = portID_to_abb(str(int(get_port_from_route(route_data, route_leg_id, arrival=True))))\n",
    "        departure_port_id = portID_to_abb(str(int(get_port_from_route(route_data, route_leg_id, departure=True))))\n",
    "        route_id = route_leg_id.split(\"-\")[0]\n",
    "\n",
    "        #Create the shared plot\n",
    "        route_figure = plt.figure()\n",
    "        plt.suptitle(f\"Route {route_id}, Leg {departure_port_id} to {arrival_port_id}\")\n",
    "\n",
    "        #Get the min x and max x for the histogram\n",
    "        min_x = route_data.loc[route_data[\"route_leg_id\"] == route_leg_id, \"sailing_time\"].min()\n",
    "        max_x = route_data.loc[route_data[\"route_leg_id\"] == route_leg_id, \"sailing_time\"].max()\n",
    "\n",
    "        for vessel in route_vessels: \n",
    "            #verify the vessel has sailed on the route\n",
    "            if route_data.loc[(route_data[\"vessel_id\"] == vessel) & (route_data[\"route_leg_id\"] == route_leg_id)].empty:\n",
    "                continue\n",
    "\n",
    "\n",
    "            #Determine the subplot location\n",
    "            unique_vessels_for_route = route_data.loc[route_data[\"route_leg_id\"] == route_leg_id, \"vessel_id\"].nunique()\n",
    "            index_array_for_vessel_on_route = route_data.loc[route_data[\"route_leg_id\"] == route_leg_id, \"vessel_id\"].unique()\n",
    "            plt.subplot(1 if unique_vessels_for_route <= 3 else 2, \n",
    "                        unique_vessels_for_route if unique_vessels_for_route <= 3 else 3, \n",
    "                        np.where(index_array_for_vessel_on_route == vessel)[0][0] + 1)\n",
    "            \n",
    "            #Plot the data\n",
    "            route_data.loc[(route_data[\"vessel_id\"] == vessel) & (route_data[\"route_leg_id\"] == route_leg_id)][\"sailing_time\"].hist(\n",
    "                bins=20, alpha=0.5, label=f\"Vessel {vessel}\", range=[min_x, max_x])\n",
    "\n",
    "            #Set the title, labels, and grid\n",
    "            plt.title(f\"Vessel {vessel}\")\n",
    "            plt.xlabel(\"Sailing Time (m)\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.grid(False)\n",
    "            \n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{FIGURES_DIR}/Route{route_id}_SubPlots_{departure_port_id+arrival_port_id}.png\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "make_subplot_histograms_for_legs(Route5_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df61c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analyze_data.loc[(all_analyze_data[\"route_id\"] == 9) & (all_analyze_data[\"route_leg_id\"].apply(lambda x: x.split(\"-\")[0]) == \"5\")]\n",
    "all_analyze_data.loc[(all_analyze_data[\"route_id\"] == 5) & (all_analyze_data[\"route_leg_id\"].apply(lambda x: x.split(\"-\")[0]) == \"9\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7295bc",
   "metadata": {},
   "source": [
    "##Simple sim without ferries mattering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731d7ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "route = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
